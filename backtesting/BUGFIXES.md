# Backtest Data Fetcher - Bug Fixes

## Issues Fixed

### 1. âŒ FileNotFoundError: 'data/' Directory
**Problem:**
```
ERROR - Error processing BTC: [Errno 2] No such file or directory: 'data/volatility_BTC.json'
```

The script was trying to write files to a `data/` directory that didn't exist.

**Solution:**
Added `os.makedirs("data", exist_ok=True)` before writing files at three locations:
- Line 227: Before saving volatility JSON files
- Line 238: Before saving parquet data files  
- Line 379: Before saving the final volatility_baseline.json

The `exist_ok=True` parameter ensures the command won't fail if the directory already exists.

### 2. âš ï¸ Deprecated Pandas Method Warning
**Problem:**
```
FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
```

**Solution:**
Changed line 104 from:
```python
df.fillna(method='ffill', inplace=True)
```

To:
```python
df.ffill(inplace=True)
```

This uses the modern pandas API that won't be deprecated in future versions.

### 3. â¬†ï¸ Increased Chunk Size (Per User Request)
**Problem:**
Fetching data in 20-day chunks was too small.

**Solution:**
Changed line 275 from:
```python
chunk_end = current_start + timedelta(days=20)
```

To:
```python
chunk_end = current_start + timedelta(days=60)
```

**Benefits:**
- Fewer API requests (faster downloads)
- Less overhead from rate limiting
- Approximately 3x faster data fetching

## Summary of Changes

| Line | Before | After | Reason |
|------|--------|-------|--------|
| 104 | `df.fillna(method='ffill', ...)` | `df.ffill(...)` | Fix deprecation warning |
| 227 | _(no directory creation)_ | `os.makedirs("data", exist_ok=True)` | Ensure data/ exists |
| 238 | _(no directory creation)_ | `os.makedirs("data", exist_ok=True)` | Ensure data/ exists |
| 275 | `timedelta(days=20)` | `timedelta(days=60)` | Increase chunk size |
| 379 | _(no directory creation)_ | `os.makedirs("data", exist_ok=True)` | Ensure data/ exists |

## File Output Structure

After running the fixed script, files will be created in the `data/` directory:

```
tradingbot/
â”œâ”€â”€ backtesting/
â”‚   â””â”€â”€ backtest_data_fetcher.py (fixed)
â””â”€â”€ data/  (auto-created)
    â”œâ”€â”€ backtest_data_BTC.parquet
    â”œâ”€â”€ backtest_data_ETH.parquet
    â”œâ”€â”€ backtest_data_SOL.parquet
    â”œâ”€â”€ backtest_data_EUR.parquet
    â”œâ”€â”€ backtest_data_GBP.parquet
    â”œâ”€â”€ backtest_data_JPY.parquet
    â”œâ”€â”€ volatility_BTC.json
    â”œâ”€â”€ volatility_ETH.json
    â”œâ”€â”€ volatility_SOL.json
    â”œâ”€â”€ volatility_EUR.json
    â”œâ”€â”€ volatility_GBP.json
    â”œâ”€â”€ volatility_JPY.json
    â””â”€â”€ volatility_baseline.json
```

## Expected Performance Improvement

### Before (20-day chunks):
- Total chunks needed: ~60 requests per asset
- Total fetching time: ~90 seconds per asset
- **Total for 6 assets: ~9 minutes**

### After (60-day chunks):
- Total chunks needed: ~20 requests per asset  
- Total fetching time: ~30 seconds per asset
- **Total for 6 assets: ~3 minutes**

**~66% time reduction** ğŸš€

## How to Run

```bash
python backtesting/backtest_data_fetcher.py
```

The script will:
1. âœ… Automatically create the `data/` directory if it doesn't exist
2. âœ… Fetch data from cTrader API (2020-2025)
3. âœ… Calculate technical indicators
4. âœ… Save volatility baselines for training
5. âœ… Save normalized backtest data as parquet files
6. âœ… No more FileNotFoundError!

## Testing

To verify the fix works:
1. Delete the `data/` directory if it exists
2. Run the script
3. Check that the `data/` directory is created automatically
4. Verify all 13 files are created (6 parquet + 6 volatility + 1 baseline)

# Backtesting Module

Comprehensive backtesting infrastructure for the RL Trading Bot with stage-aware functionality.

## Overview

This module provides backtesting capabilities for evaluating trained models on 2025 hold-out data, with full support for all three curriculum learning stages.

## Directory Structure

```
backtest/
├── __init__.py                      # Module initialization
├── data_fetcher_backtest.py         # Fetch 2025 data from cTrader
├── backtest.py                      # Main backtesting script
├── compare_stages.py                # Compare performance across stages
├── data/                            # 2025 backtest data (generated)
│   ├── EURUSD_5m_2025.parquet
│   ├── GBPUSD_5m_2025.parquet
│   ├── USDJPY_5m_2025.parquet
│   ├── USDCHF_5m_2025.parquet
│   └── XAUUSD_5m_2025.parquet
└── results/                         # Backtest outputs (generated)
    ├── metrics_stage1_*.json
    ├── trades_stage1_*.csv
    ├── equity_curve_stage1_*.png
    └── asset_breakdown_stage1_*.csv
```

## Quick Start

### 1. Download 2025 Data

First, fetch the hold-out test data (Jan 1 - Dec 3, 2025):

```bash
python backtest/data_fetcher_backtest.py
```

This will download 5-minute OHLCV data for all 5 assets to `backtest/data/`.

### 2. Run Backtesting

Test a trained model on 2025 data:

```bash
# Stage 1 (Direction only)
python backtest/backtest.py --model models/checkpoints/stage_1_final.zip --stage 1

# Stage 2 (Direction + Position Sizing)
python backtest/backtest.py --model models/checkpoints/stage_2_final.zip --stage 2

# Stage 3 (Full Control)
python backtest/backtest.py --model models/checkpoints/stage_3_final.zip --stage 3
```

### 3. Compare Stages

After running backtests for all stages, compare their performance:

```bash
python backtest/compare_stages.py --results-dir backtest/results
```

## Command-Line Options

### backtest.py

```
--model PATH          Path to trained model (.zip file) [REQUIRED]
--stage {1,2,3}       Curriculum stage [REQUIRED]
--data-dir PATH       Path to backtest data (default: backtest/data)
--output-dir PATH     Path to save results (default: backtest/results)
--episodes INT        Number of episodes to run (default: 50)
```

### compare_stages.py

```
--results-dir PATH    Directory containing backtest results (default: backtest/results)
```

## Metrics Tracked

Per PRD Section 8.1, the following metrics are calculated:

### Primary Metrics
- **Profit Factor** (PRIMARY): Gross profit / gross loss
- **Total Return**: (Final equity - starting capital) / starting capital
- **Sharpe Ratio**: Risk-adjusted returns
- **Max Drawdown**: Largest peak-to-trough decline
- **Win Rate**: Winning trades / total trades

### Secondary Metrics
- Average RR Ratio (TP/SL)
- Trade Frequency (trades per day)
- Average Hold Time (minutes)
- Per-asset performance breakdown
- Session analysis (future enhancement)

## PRD Success Criteria

The backtest automatically checks against PRD Section 8.1 criteria:

| Metric | Target | Minimum Acceptable |
|--------|--------|-------------------|
| Profit Factor | > 1.5 | > 1.3 |
| Max Drawdown | < 15% | < 20% |
| Sharpe Ratio | > 1.5 | > 1.0 |
| Win Rate | > 50% | > 45% |

## Output Files

All outputs are saved to `backtest/results/` with timestamps:

1. **Metrics JSON** (`metrics_stage{N}_{timestamp}.json`)
   - Complete metrics dictionary
   - Easy to parse programmatically

2. **Trade Log CSV** (`trades_stage{N}_{timestamp}.csv`)
   - Detailed record of every trade
   - Columns: timestamp, asset, action, size, entry_price, sl, tp, exit_price, pnl, fees, equity

3. **Equity Curve Plot** (`equity_curve_stage{N}_{timestamp}.png`)
   - Visual representation of equity over time
   - Drawdown shading

4. **Asset Breakdown CSV** (`asset_breakdown_stage{N}_{timestamp}.csv`)
   - Performance metrics per asset
   - Identifies which assets are most/least profitable

5. **Stage Comparison** (`stage_comparison.csv` and `.png`)
   - Side-by-side comparison of all stages
   - Generated by `compare_stages.py`

## Stage-Specific Behavior

The backtesting script automatically handles different action spaces:

### Stage 1: Direction Only
- Action space: 5 outputs (1 per asset)
- Fixed position size: 25%
- Fixed SL: 1.5× ATR
- Fixed TP: 2.5× ATR

### Stage 2: Direction + Position Sizing
- Action space: 10 outputs (2 per asset)
- Variable position size: 0-100%
- Fixed SL: 1.5× ATR
- Fixed TP: 2.5× ATR

### Stage 3: Full Control
- Action space: 20 outputs (4 per asset)
- Variable position size: 0-100%
- Variable SL: 0.5-3.0× ATR
- Variable TP: 1.5-5.0× ATR

## Example Workflow

```bash
# 1. Download 2025 data (one-time setup)
python backtest/data_fetcher_backtest.py

# 2. Backtest Stage 1 model
python backtest/backtest.py \
    --model models/checkpoints/ppo_stage1_1000000_steps.zip \
    --stage 1 \
    --episodes 100

# 3. Backtest Stage 2 model
python backtest/backtest.py \
    --model models/checkpoints/ppo_stage2_2500000_steps.zip \
    --stage 2 \
    --episodes 100

# 4. Backtest Stage 3 model
python backtest/backtest.py \
    --model models/checkpoints/stage_3_final.zip \
    --stage 3 \
    --episodes 100

# 5. Compare all stages
python backtest/compare_stages.py
```

## Notes

- **Deterministic Evaluation**: Models are run in deterministic mode for reproducible results
- **VecNormalize Support**: Automatically loads normalization stats if available
- **2025 Data Range**: Jan 1, 2025 to Dec 3, 2025 (nearly full year)
- **Episode Length**: Each episode represents 1 trading day (288 steps @ 5min candles)

## Troubleshooting

### "Model file not found"
Ensure you've trained a model first using `src/train.py` or provide the correct path to an existing model.

### "Data directory not found"
Run `python backtest/data_fetcher_backtest.py` to download 2025 data first.

### "No trades to analyze"
The model may not be generating any trades. Check:
- Model is loaded correctly
- Data is valid
- Environment configuration matches training setup

## Integration with Training

The backtesting module is designed to work seamlessly with models trained using `src/train.py`. Models are saved with VecNormalize stats, which are automatically loaded during backtesting for consistent feature normalization.

## Future Enhancements

- [ ] Session-based analysis (Asian/London/NY performance)
- [ ] Monte Carlo simulation for robustness testing
- [ ] Walk-forward analysis
- [ ] Parameter sensitivity analysis
- [ ] Real-time backtesting with live data feed

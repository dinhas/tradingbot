ppo:
  learning_rate: 0.0001
  n_steps: 512
  batch_size: 64
  gamma: 0.0
  gae_lambda: 0.95
  ent_coef: 0.03
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: 0.02
  total_timesteps: 1000000
  policy_kwargs:
    net_arch: [128, 128]

env:
  reward_scaling: 1.0
  reward_mode: "binary" # Options: "pnl", "binary"
  penalty_factors:
    missed_win: 0.5
    loss_avoided: 0.1
  seed: 75
  dataset_path: "TradeGuard/data/tradeguard_dataset.parquet"

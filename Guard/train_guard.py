"""
Train TradeGuard Model (LightGBM)
---------------------------------
Trains a LightGBM classifier to filter trades generated by the Alpha+Risk system.
- Input: Market Features (140) + Risk Params (3) + Asset ID
- Target: Label (1=Win, 0=Loss)
"""

import os
import glob
import logging
import joblib
import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score
from sklearn.model_selection import train_test_split

# Configure Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def train_guard():
    DATA_DIR = "Guard/data"
    MODEL_DIR = "Guard/models"
    os.makedirs(MODEL_DIR, exist_ok=True)
    
    # 1. Load Data
    logger.info("Loading dataset chunks...")
    files = sorted(glob.glob(os.path.join(DATA_DIR, "*.parquet")))
    
    if not files:
        logger.error("No data found! Run generate_dataset.py first.")
        return
        
    # Read and concatenate
    dfs = []
    for f in files:
        dfs.append(pd.read_parquet(f))
    
    df = pd.concat(dfs, ignore_index=True)
    logger.info(f"Total dataset size: {len(df)} rows")
    
    # 2. Preprocessing
    # Features: f_0 to f_139, risk_raw, sl_mult, tp_mult
    feature_cols = [c for c in df.columns if c.startswith('f_')]
    feature_cols += ['risk_raw', 'sl_mult', 'tp_mult']
    
    # Handle Asset ID (Categorical)
    # LightGBM handles categorical features natively if typed as 'category'
    df['asset'] = df['asset'].astype('category')
    feature_cols.append('asset')
    
    X = df[feature_cols]
    y = df['label']
    
    # 3. Time-Series Split (No random shuffle!)
    # We want to test on the "future"
    split_idx = int(len(df) * 0.80)
    
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
    
    logger.info(f"Training set: {len(X_train)}, Test set: {len(X_test)}")
    logger.info(f"Baseline Win Rate (Train): {y_train.mean():.2%}")
    logger.info(f"Baseline Win Rate (Test): {y_test.mean():.2%}")
    
    # 4. Train LightGBM
    logger.info("Training LightGBM Classifier...")
    
    # Parameters optimized for tabular financial data
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'n_jobs': -1
    }
    
    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=['asset'])
    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=['asset'])
    
    model = lgb.train(
        params,
        train_data,
        num_boost_round=1000,
        valid_sets=[train_data, test_data],
        callbacks=[
            lgb.early_stopping(stopping_rounds=50),
            lgb.log_evaluation(period=100)
        ]
    )
    
    # 5. Evaluation
    logger.info("Evaluating model...")
    y_pred_prob = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred = (y_pred_prob > 0.5).astype(int)
    
    logger.info("\n" + classification_report(y_test, y_pred))
    logger.info(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    logger.info(f"Precision: {precision_score(y_test, y_pred):.4f}")
    
    # 6. Save Model
    model_path = os.path.join(MODEL_DIR, "tradeguard_lgbm.txt")
    model.save_model(model_path)
    logger.info(f"Model saved to {model_path}")

if __name__ == "__main__":
    train_guard()

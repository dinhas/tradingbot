default:
  # =========================================================================
  # PRODUCTION CONFIG — Stable Training for Clean Reward System
  # =========================================================================
  
  # Learning Rate: Moderate for stability
  learning_rate: 0.0003
  
  # Rollout Settings
  n_steps: 2048
  batch_size: 256
  n_epochs: 10
  # Gradient updates per rollout: (2048/256) * 10 = 80
  
  # Temporal Discounting
  gamma: 0.99
  gae_lambda: 0.95
  
  # PPO Clipping
  clip_range: 0.2
  
  # Loss Coefficients
  vf_coef: 0.5
  
  # Gradient Clipping
  max_grad_norm: 0.5
  
  # Logging
  verbose: 1
  tensorboard_log: null  # Disabled (tensorboard not installed)
  
  # Training Budget
  total_timesteps: 1500000
  
  # Network Architecture
  policy_kwargs:
    net_arch: [256, 256, 128]
    activation_fn: "ReLU"

# Stage-Specific Entropy (Exploration vs Exploitation)
stages:
  1:
    # Stage 1: Direction Only — High exploration
    ent_coef: 0.02
  2:
    # Stage 2: Direction + Position Size — Moderate exploration
    ent_coef: 0.01
  3:
    # Stage 3: Direction + Size + SL/TP — Focus on exploitation
    ent_coef: 0.005

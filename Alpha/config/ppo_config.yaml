# =========================================================================
# OPTIMIZED ALPHA CONFIG â€” Fast Convergence for 2.25M Steps
# =========================================================================

# Learning Rate: Increased to standard baseline for faster adaptation
learning_rate: 0.0003

# Rollout Settings: 
# Reduced n_steps to 1024 to increase update frequency (approx 120 updates per 1M steps)
n_steps: 1024
batch_size: 256
n_epochs: 10

# Temporal Discounting
gamma: 0.95
gae_lambda: 0.95

# PPO Clipping
clip_range: 0.2
clip_range_vf: null

# Entropy Regularization: Reduced to 0.01 to balance exploration with 
# stability, helping to mitigate excessive trade churning and allow 
# earlier exploitation of learned patterns.
ent_coef: 0.01

# Loss Coefficients
vf_coef: 0.5

# Gradient Clipping
max_grad_norm: 0.5

# Training Budget
total_timesteps: 1500000

# Network Architecture
policy_kwargs:
  net_arch: [192, 192, 96]
  activation_fn: "ReLU"